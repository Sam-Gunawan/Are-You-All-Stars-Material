{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ARE YOU ALL STARS MATERIAL?**\n",
    "\n",
    "In this notebook, we will explore whether a player with certain stats is All-Stars material or not using a machine learning approach. We will start by gathering and preparing our dataset, which consists of comprehensive statistics of NBA players, both current and past. This data has been meticulously collected and verified from the official [NBA website](https://www.nba.com/).\n",
    "\n",
    "We will then proceed with data preprocessing, feature selection, and model training to predict the likelihood of a player being an All-Star. Let's dive into the exciting world of basketball analytics and machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we import the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert each csv to dataframes using Pandas and then combining the non all-star players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars_df = pd.read_csv('players_dataset/All_Stars.csv', header=0)\n",
    "atlantic_df = pd.read_csv('players_dataset/Atlantic.csv', header=0)\n",
    "central_df = pd.read_csv('players_dataset/Central.csv', header=0)\n",
    "northwest_df = pd.read_csv('players_dataset/Northwest.csv', header=0)\n",
    "pacific_df = pd.read_csv('players_dataset/Pacific.csv', header=0)\n",
    "southeast_df = pd.read_csv('players_dataset/Southeast.csv', header=0)\n",
    "southwest_df = pd.read_csv('players_dataset/Southwest.csv', header=0)\n",
    "\n",
    "divisions = [southwest_df, southeast_df, pacific_df, northwest_df, central_df, atlantic_df]\n",
    "non_all_star_df = pd.concat(divisions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign binary labels for all-stars and non all-stars. In our case, 1 denotes all-star, 0 denotes otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_players = non_all_star_df[non_all_star_df['Name'].isin(all_stars_df['Name'])]\n",
    "print(common_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars_df[\"Label\"] = 1  # All-Star\n",
    "non_all_star_df[\"Label\"] = 0  # Non-All-Star\n",
    "\n",
    "all_players_df = pd.concat([all_stars_df, non_all_star_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we clean up the data and make sure Python can read each category correctly. E.g., the player's height is still in feet and inches format, we'd have to make sure that Python can read it as inches (with number type). For simplicity in code, we used Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the numerical value of the weight, removing the \"lbs\" suffix\n",
    "all_players_df[\"Weight\"] = all_players_df[\"Weight\"].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Converting the height to inches from feet and inches format\n",
    "height_split = all_players_df[\"Height\"].str.extract(r'(?P<feet>\\d+)\\'(?P<inches>\\d+)')\n",
    "all_players_df[\"Height\"] = height_split[\"feet\"].astype(float) * 12 + height_split[\"inches\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_players_df[[\"Weight\", \"Height\", \"PPG (Points per game)\", \"RPG (Rebound per game)\", \"APG (Assists per game)\", \"PIE (Player Impact Estimate)\"]][0:5])\n",
    "print(all_players_df[\"Label\"][0:5].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Metrics\n",
    "Before we build our classifiers, let's first define the different distance metrics we will use to measure similarity between data points. These metrics help determine how \"close\" two players are based on their stats. We'll be using 3 different metrics for comparison:\n",
    "1. Cosine Similarity\n",
    "2. Euclidean distance\n",
    "3. Mahalanobis distance\n",
    "<br>\n",
    "\n",
    "### Cosine Similarity\n",
    "Cosine similarity measures the similarity between two vectors based on the angle between them. Cosine similarity measures the similarity between two vectors based on the angle between them. It is useful when the magnitude of the values does not matter, only their direction (e.g., comparing player performance trends rather than raw numbers). We use numpy's extensive mathematical functions for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors. The cosine similarity is a measure of similarity between two non-zero vectors of an inner product.\"\"\"\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "Euclidean distance measures the straight-line distance between two points in feature space. It is the most commonly used metric for KNN as it treats all features equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(v1, v2):\n",
    "    \"\"\"Calculate euclidean distance between two vectors. For every dimension, calculate the difference between the two vectors, square it, sum all the squared differences, and take the square root of the sum.\"\"\"\n",
    "    return np.sqrt(np.sum((np.array(v1) - np.array(v2))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Distance\n",
    "Mahalanobis distance accounts for correlations between variables and scales the distances accordingly. Mahalanobis distance accounts for correlations between variables and scales the distances accordingly. It is particularly useful when features (e.g., height and weight) are correlated. In this case, we use a library to get the mahalanobis distance (just so that they can handle the matrix multiplication behind the scenes). Our function definition helps with inverting the covariance matrix before using the library's function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(v1, v2, cov_matrix):\n",
    "    \"\"\"Calculate the Mahalanobis distance between two vectors. The Mahalanobis distance is a measure of the distance between a point and a distribution.\"\"\"\n",
    "    inv_cov = np.linalg.inv(cov_matrix)\n",
    "    return mahalanobis(v1, v2, inv_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour\n",
    "\n",
    "Now that all data is tidy and clean, we start with training the model using K-Nearest Neighbour (KNN). KNN is a supervised machine learning algorithm used for classification and regression. It works by finding the k closest points (neighbors) to a given data point and assigning a label based on the majority vote of those neighbors.\n",
    "\n",
    "Before applying KNN, we need to split our dataset into a **training set** and a **test set**. The training set is used to teach the model, while the test set evaluates its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let x = features\n",
    "# Let y = labels\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_players_df[[\"Height\", \"Weight\"]], all_players_df[\"Label\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def dot(X, Y):\n",
    "    \"\"\"Compute the dot product of two vectors.\"\"\"\n",
    "    return sum(x * y for x, y in zip(X, Y))\n",
    "\n",
    "def norm(X):\n",
    "    \"\"\"Compute the Euclidean norm of a vector.\"\"\"\n",
    "    return sum(x ** 2 for x in X) ** 0.5\n",
    "\n",
    "def cosine_similarity(X, Y):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return dot(X, Y) / (norm(X) * norm(Y))\n",
    "\n",
    "# Load All-Star and Non-All-Star player data\n",
    "all_stars_df = pd.read_csv('players_dataset/All_Stars.csv', header=0)\n",
    "southwest_df = pd.read_csv('players_dataset/Southwest.csv', header=0)\n",
    "southeast_df = pd.read_csv('players_dataset/Southeast.csv', header=0)\n",
    "pacific_df = pd.read_csv('players_dataset/Pacific.csv', header=0)\n",
    "northwest_df = pd.read_csv('players_dataset/Northwest.csv', header=0)\n",
    "central_df = pd.read_csv('players_dataset/Central.csv', header=0)\n",
    "atlantic_df = pd.read_csv('players_dataset/Atlantic.csv', header=0)\n",
    "\n",
    "# Combine all non-All-Star data\n",
    "divisions = [southwest_df, southeast_df, pacific_df, northwest_df, central_df, atlantic_df]\n",
    "non_all_star_df = pd.concat(divisions, ignore_index=True)\n",
    "\n",
    "# Assign labels\n",
    "all_stars_df[\"Label\"] = 1  # All-Star\n",
    "non_all_star_df[\"Label\"] = 0  # Non-All-Star\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat([all_stars_df, non_all_star_df], ignore_index=True)\n",
    "\n",
    "# Convert weight to numeric (removing 'lb')\n",
    "data[\"Weight\"] = data[\"Weight\"].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Convert height to inches\n",
    "height_split = data[\"Height\"].str.extract(r'(?P<feet>\\d+)\\'(?P<inches>\\d+)')\n",
    "data[\"Height\"] = height_split[\"feet\"].astype(float) * 12 + height_split[\"inches\"].astype(float)\n",
    "\n",
    "# Select relevant numerical columns\n",
    "features = [\"Weight\", \"Height\", \"PPG (Points per game)\", \"RPG (Rebound per game)\", \"APG (Assists per game)\", \"PIE (Player Impact Estimate)\"]\n",
    "players_stats_original = data[features].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Extract labels\n",
    "labels = data[\"Label\"].to_numpy()\n",
    "\n",
    "# k-NN Classification with predefined k values\n",
    "def predict_all_star(new_player, k):\n",
    "    new_player = np.array(new_player)\n",
    "    dataset = players_stats_original.to_numpy()\n",
    "    \n",
    "    # Compute similarities to all players\n",
    "    similarities = [(cosine_similarity(new_player, dataset[i]), labels[i], data.iloc[i][\"Name\"], *players_stats_original.iloc[i]) for i in range(len(dataset))]\n",
    "    \n",
    "    # Sort by highest similarity (descending order)\n",
    "    sorted_similarities = sorted(similarities, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Select top-k nearest neighbors\n",
    "    top_k = sorted_similarities[:k]\n",
    "    \n",
    "    # Count votes\n",
    "    all_star_votes = sum(1 for sim in top_k if sim[1] == 1)\n",
    "    not_all_star_votes = sum(1 for sim in top_k if sim[1] == 0)\n",
    "    \n",
    "    # Determine final classification\n",
    "    prediction = \"All-Star\" if all_star_votes > not_all_star_votes else \"Not All-Star\"\n",
    "    \n",
    "    return prediction, top_k\n",
    "\n",
    "\n",
    "\n",
    "def get_valid_input(prompt, convert_func=float):\n",
    "    while True:\n",
    "        try:\n",
    "            value = convert_func(input(prompt))\n",
    "            return value\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid value.\")\n",
    "\n",
    "# print(\"Enter player stats:\")\n",
    "name = input(\"Name: \")\n",
    "weight = get_valid_input(\"Weight (lbs): \")\n",
    "feet = get_valid_input(\"Height (feet): \", int)\n",
    "inches = get_valid_input(\"Height (inches): \", int)\n",
    "height = feet * 12 + inches\n",
    "ppg = get_valid_input(\"PPG (Points per game): \")\n",
    "rpg = get_valid_input(\"RPG (Rebound per game): \")\n",
    "apg = get_valid_input(\"APG (Assists per game): \")\n",
    "pie = get_valid_input(\"PIE (Player Impact Estimate): \")\n",
    "\n",
    "new_player = [weight, height, ppg, rpg, apg, pie]\n",
    "\n",
    "# Predict for k values 7, 9, and 11\n",
    "for k in [7, 9, 11]:\n",
    "    prediction, top_k = predict_all_star(new_player, k)\n",
    "    print(f\"\\nK = {k}\")\n",
    "    print(f\"{'Name':<15}{'Weight':<10}{'Height':<10}{'PPG':<10}{'RPG':<10}{'APG':<10}{'PIE':<10}{'Cosine Similarity':<20}{'Label':<15}\")\n",
    "    for player in top_k:\n",
    "        label = \"All-Star\" if player[1] == 1 else \"Not All-Star\"\n",
    "        print(f\"{player[2]:<15}{player[3]:<10.2f}{player[4]:<10.2f}{player[5]:<10.2f}{player[6]:<10.2f}{player[7]:<10.2f}{player[8]:<10.2f}{player[0]:<20.4f}{label:<15}\")\n",
    "    print(f\"{name:<15}{weight:<10.2f}{height:<10.2f}{ppg:<10.2f}{rpg:<10.2f}{apg:<10.2f}{pie:<10.2f}{'':<20}{prediction:<15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating the euclidian distance of two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(arr1, arr2):\n",
    "    # should be able to take in 2 array (or any number of values) and return the euclidian distance between them\n",
    "    a1 = np.array(arr1)\n",
    "    a2 = np.array(arr2)\n",
    "    return np.sqrt(np.sum((a1 - a2)**2))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for the centroid classifier, checks for euclidian and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start for centroid classifier\n",
    "def centroid_classifier(new_player):\n",
    "    # Calculate average statistics for All-Stars and Non-All-Stars directly from the DataFrames and change it to a numpy array\n",
    "    all_star_averages = all_stars_df[features].mean().to_numpy()\n",
    "    non_all_star_averages = non_all_star_df[features].mean().to_numpy()\n",
    "    \n",
    "    centroid_check_euclidian(new_player,all_star_averages,non_all_star_averages)\n",
    "    centroid_check_cosine(new_player,all_star_averages,non_all_star_averages)\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with euclidian distance\n",
    "def centroid_check_euclidian(new_player, all_star_avg, non_all_satr_avg):\n",
    "    # Calculate Euclidean distances to both centroids\n",
    "    euclidian_distance_to_all_star = euclidian_distance(new_player, all_star_avg)\n",
    "    eudlidian_distance_to_non_all_star = euclidian_distance(new_player, non_all_satr_avg)\n",
    "\n",
    "    # Classify based on the closer centroid\n",
    "    if euclidian_distance_to_all_star < eudlidian_distance_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with cosine similarity\n",
    "def centroid_check_cosine(new_player, all_star_avg, non_all_satr_avg):\n",
    "    cosine_similarity_to_all_star = cosine_similarity(new_player, all_star_avg)\n",
    "    cosine_similarity_to_non_all_star = cosine_similarity(new_player, non_all_satr_avg)\n",
    "    \n",
    "    # Classify based on which centroid is larger (closer to 1)\n",
    "    if cosine_similarity_to_all_star > cosine_similarity_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with mahalobis distance\n",
    "def centroid_mahalobis_distance(new_player, all_star_avg, non_all_satr_avg):\n",
    "    mahalobis_distance_to_all_star = mahalobis_distance(new_player, all_star_avg)\n",
    "    mahalobis_distance_to_non_all_star = mahalobis_distance(new_player, non_all_satr_avg)\n",
    "    \n",
    "    # Classify based on the closer centroid\n",
    "    if mahalobis_distance_to_all_star < mahalobis_distance_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
