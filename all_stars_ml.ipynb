{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARE YOU ALL STARS MATERIAL?\n",
    "\n",
    "In this notebook, we will explore whether a player with certain stats is All-Stars material or not using a machine learning approach. We will start by gathering and preparing our dataset, which consists of comprehensive statistics of NBA players, both current and past. This data has been meticulously collected and verified from the official [NBA website](https://www.nba.com/).\n",
    "\n",
    "We will then proceed with data preprocessing, feature selection, and model training to predict the likelihood of a player being an All-Star. Let's dive into the exciting world of basketball analytics and machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we import the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert each csv to dataframes using Pandas and then combining the non all-star players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars_df = pd.read_csv('players_dataset/All_Stars.csv', header=0)\n",
    "atlantic_df = pd.read_csv('players_dataset/Atlantic.csv', header=0)\n",
    "central_df = pd.read_csv('players_dataset/Central.csv', header=0)\n",
    "northwest_df = pd.read_csv('players_dataset/Northwest.csv', header=0)\n",
    "pacific_df = pd.read_csv('players_dataset/Pacific.csv', header=0)\n",
    "southeast_df = pd.read_csv('players_dataset/Southeast.csv', header=0)\n",
    "southwest_df = pd.read_csv('players_dataset/Southwest.csv', header=0)\n",
    "\n",
    "divisions = [southwest_df, southeast_df, pacific_df, northwest_df, central_df, atlantic_df]\n",
    "non_all_star_df = pd.concat(divisions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign binary labels for all-stars and non all-stars. In our case, 1 denotes all-star, 0 denotes otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Name  Weight Height  PPG (Points per game)  \\\n",
      "27               Trae Young   164lb   6'1\"                   23.7   \n",
      "35              Tyler Herro   195lb   6'5\"                   23.9   \n",
      "84          Anthony Edwards  225 lb   6'4\"                   27.5   \n",
      "85           Jalen Williams  211 lb   6'5\"                   21.0   \n",
      "89  Shai Gilgeous-Alexander  195 lb   6'6\"                   32.5   \n",
      "95           Keyonte George  185 lb   6'4\"                   16.4   \n",
      "\n",
      "    RPG (Rebound per game)  APG (Assists per game)  \\\n",
      "27                     3.2                    11.5   \n",
      "35                     5.5                     5.5   \n",
      "84                     5.8                     4.5   \n",
      "85                     5.5                     5.1   \n",
      "89                     5.1                     6.1   \n",
      "95                     3.6                     6.0   \n",
      "\n",
      "    PIE (Player Impact Estimate)  \n",
      "27                          12.4  \n",
      "35                          13.7  \n",
      "84                          13.8  \n",
      "85                          13.7  \n",
      "89                          20.5  \n",
      "95                           9.1  \n"
     ]
    }
   ],
   "source": [
    "common_players = non_all_star_df[non_all_star_df['Name'].isin(all_stars_df['Name'])]\n",
    "print(common_players)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars_df[\"Label\"] = 1  # All-Star\n",
    "non_all_star_df[\"Label\"] = 0  # Non-All-Star\n",
    "\n",
    "all_players_df = pd.concat([all_stars_df, non_all_star_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we clean up the data and make sure Python can read each category correctly. E.g., the player's height is still in feet and inches format, we'd have to make sure that Python can read it as inches (with number type). For simplicity in code, we used Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the numerical value of the weight, removing the \"lbs\" suffix\n",
    "all_players_df[\"Weight\"] = all_players_df[\"Weight\"].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Converting the height to inches from feet and inches format\n",
    "height_split = all_players_df[\"Height\"].str.extract(r'(?P<feet>\\d+)\\'(?P<inches>\\d+)')\n",
    "all_players_df[\"Height\"] = height_split[\"feet\"].astype(float) * 12 + height_split[\"inches\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour\n",
    "\n",
    "Now that all data is tidy and clean, we start with training the model using K-Nearest Neighbour (KNN). We'll be using 2 metrics: Cosine Similarity and Euclidian Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def dot(X, Y):\n",
    "    \"\"\"Compute the dot product of two vectors.\"\"\"\n",
    "    return sum(x * y for x, y in zip(X, Y))\n",
    "\n",
    "def norm(X):\n",
    "    \"\"\"Compute the Euclidean norm of a vector.\"\"\"\n",
    "    return sum(x ** 2 for x in X) ** 0.5\n",
    "\n",
    "def cosine_similarity(X, Y):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return dot(X, Y) / (norm(X) * norm(Y))\n",
    "\n",
    "# Load All-Star and Non-All-Star player data\n",
    "all_stars_df = pd.read_csv('players_dataset/All_Stars.csv', header=0)\n",
    "southwest_df = pd.read_csv('players_dataset/Southwest.csv', header=0)\n",
    "southeast_df = pd.read_csv('players_dataset/Southeast.csv', header=0)\n",
    "pacific_df = pd.read_csv('players_dataset/Pacific.csv', header=0)\n",
    "northwest_df = pd.read_csv('players_dataset/Northwest.csv', header=0)\n",
    "central_df = pd.read_csv('players_dataset/Central.csv', header=0)\n",
    "atlantic_df = pd.read_csv('players_dataset/Atlantic.csv', header=0)\n",
    "\n",
    "# Combine all non-All-Star data\n",
    "divisions = [southwest_df, southeast_df, pacific_df, northwest_df, central_df, atlantic_df]\n",
    "non_all_star_df = pd.concat(divisions, ignore_index=True)\n",
    "\n",
    "# Assign labels\n",
    "all_stars_df[\"Label\"] = 1  # All-Star\n",
    "non_all_star_df[\"Label\"] = 0  # Non-All-Star\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat([all_stars_df, non_all_star_df], ignore_index=True)\n",
    "\n",
    "# Convert weight to numeric (removing 'lb')\n",
    "data[\"Weight\"] = data[\"Weight\"].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Convert height to inches\n",
    "height_split = data[\"Height\"].str.extract(r'(?P<feet>\\d+)\\'(?P<inches>\\d+)')\n",
    "data[\"Height\"] = height_split[\"feet\"].astype(float) * 12 + height_split[\"inches\"].astype(float)\n",
    "\n",
    "# Select relevant numerical columns\n",
    "features = [\"Weight\", \"Height\", \"PPG (Points per game)\", \"RPG (Rebound per game)\", \"APG (Assists per game)\", \"PIE (Player Impact Estimate)\"]\n",
    "players_stats_original = data[features].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Extract labels\n",
    "labels = data[\"Label\"].to_numpy()\n",
    "\n",
    "# k-NN Classification with predefined k values\n",
    "def predict_all_star(new_player, k):\n",
    "    new_player = np.array(new_player)\n",
    "    dataset = players_stats_original.to_numpy()\n",
    "    \n",
    "    # Compute similarities to all players\n",
    "    similarities = [(cosine_similarity(new_player, dataset[i]), labels[i], data.iloc[i][\"Name\"], *players_stats_original.iloc[i]) for i in range(len(dataset))]\n",
    "    \n",
    "    # Sort by highest similarity (descending order)\n",
    "    sorted_similarities = sorted(similarities, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Select top-k nearest neighbors\n",
    "    top_k = sorted_similarities[:k]\n",
    "    \n",
    "    # Count votes\n",
    "    all_star_votes = sum(1 for sim in top_k if sim[1] == 1)\n",
    "    not_all_star_votes = sum(1 for sim in top_k if sim[1] == 0)\n",
    "    \n",
    "    # Determine final classification\n",
    "    prediction = \"All-Star\" if all_star_votes > not_all_star_votes else \"Not All-Star\"\n",
    "    \n",
    "    return prediction, top_k\n",
    "\n",
    "\n",
    "\n",
    "def get_valid_input(prompt, convert_func=float):\n",
    "    while True:\n",
    "        try:\n",
    "            value = convert_func(input(prompt))\n",
    "            return value\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid value.\")\n",
    "\n",
    "# print(\"Enter player stats:\")\n",
    "name = input(\"Name: \")\n",
    "weight = get_valid_input(\"Weight (lbs): \")\n",
    "feet = get_valid_input(\"Height (feet): \", int)\n",
    "inches = get_valid_input(\"Height (inches): \", int)\n",
    "height = feet * 12 + inches\n",
    "ppg = get_valid_input(\"PPG (Points per game): \")\n",
    "rpg = get_valid_input(\"RPG (Rebound per game): \")\n",
    "apg = get_valid_input(\"APG (Assists per game): \")\n",
    "pie = get_valid_input(\"PIE (Player Impact Estimate): \")\n",
    "\n",
    "new_player = [weight, height, ppg, rpg, apg, pie]\n",
    "\n",
    "# Predict for k values 7, 9, and 11\n",
    "for k in [7, 9, 11]:\n",
    "    prediction, top_k = predict_all_star(new_player, k)\n",
    "    print(f\"\\nK = {k}\")\n",
    "    print(f\"{'Name':<15}{'Weight':<10}{'Height':<10}{'PPG':<10}{'RPG':<10}{'APG':<10}{'PIE':<10}{'Cosine Similarity':<20}{'Label':<15}\")\n",
    "    for player in top_k:\n",
    "        label = \"All-Star\" if player[1] == 1 else \"Not All-Star\"\n",
    "        print(f\"{player[2]:<15}{player[3]:<10.2f}{player[4]:<10.2f}{player[5]:<10.2f}{player[6]:<10.2f}{player[7]:<10.2f}{player[8]:<10.2f}{player[0]:<20.4f}{label:<15}\")\n",
    "    print(f\"{name:<15}{weight:<10.2f}{height:<10.2f}{ppg:<10.2f}{rpg:<10.2f}{apg:<10.2f}{pie:<10.2f}{'':<20}{prediction:<15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating the euclidian distance of two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(arr1, arr2):\n",
    "    # should be able to take in 2 array (or any number of values) and return the euclidian distance between them\n",
    "    a1 = np.array(arr1)\n",
    "    a2 = np.array(arr2)\n",
    "    return np.sqrt(np.sum((a1 - a2)**2))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for the centroid classifier, checks for euclidian and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start for centroid classifier\n",
    "def centroid_classifier(new_player):\n",
    "    # Calculate average statistics for All-Stars and Non-All-Stars directly from the DataFrames and change it to a numpy array\n",
    "    all_star_averages = all_stars_df[features].mean().to_numpy()\n",
    "    non_all_star_averages = non_all_star_df[features].mean().to_numpy()\n",
    "    \n",
    "    centroid_check_euclidian(new_player,all_star_averages,non_all_star_averages)\n",
    "    centroid_check_cosine(new_player,all_star_averages,non_all_star_averages)\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with euclidian distance\n",
    "def centroid_check_euclidian(new_player, all_star_avg, non_all_satr_avg):\n",
    "    # Calculate Euclidean distances to both centroids\n",
    "    euclidian_distance_to_all_star = euclidian_distance(new_player, all_star_avg)\n",
    "    eudlidian_distance_to_non_all_star = euclidian_distance(new_player, non_all_satr_avg)\n",
    "\n",
    "    # Classify based on the closer centroid\n",
    "    if euclidian_distance_to_all_star < eudlidian_distance_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with cosine similarity\n",
    "def centroid_check_cosine(new, all_star_avg, non_all_satr_avg):\n",
    "    cosine_similarity_to_all_star = cosine_similarity(new_player, all_star_avg)\n",
    "    cosine_similarity_to_non_all_star = cosine_similarity(new_player, non_all_satr_avg)\n",
    "    \n",
    "    # Classify based on which centroid is larger (closer to 1)\n",
    "    if cosine_similarity_to_all_star > cosine_similarity_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with mahalobis distance\n",
    "def centroid_mahalobis_distance(new, all_star_avg, non_all_satr_avg):\n",
    "    mahalobis_distance_to_all_star = mahalobis_distance(new_player, all_star_avg)\n",
    "    mahalobis_distance_to_non_all_star = mahalobis_distance(new_player, non_all_satr_avg)\n",
    "    \n",
    "    # Classify based on the closer centroid\n",
    "    if mahalobis_distance_to_all_star < mahalobis_distance_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
