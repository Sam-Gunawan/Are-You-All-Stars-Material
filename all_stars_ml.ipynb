{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ARE YOU ALL STARS MATERIAL?**\n",
    "\n",
    "In this notebook, we will explore whether a player with certain stats is All-Stars material or not using a machine learning approach. We will start by gathering and preparing our dataset, which consists of comprehensive statistics of NBA players, both current and past. This data has been meticulously collected and verified from the official [NBA website](https://www.nba.com/).\n",
    "\n",
    "We will then proceed with data preprocessing, feature selection, and model training to predict the likelihood of a player being an All-Star. Let's dive into the exciting world of basketball analytics and machine learning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we import the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial.distance import mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then convert each csv to dataframes using Pandas and then combining the non all-star players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars_df = pd.read_csv('players_dataset/All_Stars.csv', header=0)\n",
    "atlantic_df = pd.read_csv('players_dataset/Atlantic.csv', header=0)\n",
    "central_df = pd.read_csv('players_dataset/Central.csv', header=0)\n",
    "northwest_df = pd.read_csv('players_dataset/Northwest.csv', header=0)\n",
    "pacific_df = pd.read_csv('players_dataset/Pacific.csv', header=0)\n",
    "southeast_df = pd.read_csv('players_dataset/Southeast.csv', header=0)\n",
    "southwest_df = pd.read_csv('players_dataset/Southwest.csv', header=0)\n",
    "\n",
    "divisions = [southwest_df, southeast_df, pacific_df, northwest_df, central_df, atlantic_df]\n",
    "non_all_star_df = pd.concat(divisions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign binary labels for all-stars and non all-stars. In our case, 1 denotes all-star, 0 denotes otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stars_df[\"Label\"] = 1  # All-Star\n",
    "non_all_star_df[\"Label\"] = 0  # Non-All-Star\n",
    "\n",
    "all_players_df = pd.concat([all_stars_df, non_all_star_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we clean up the data and make sure Python can read each category correctly. E.g., the player's height is still in feet and inches format, we'd have to make sure that Python can read it as inches (with number type). For simplicity in code, we used Regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the numerical value of the weight, removing the \"lbs\" suffix\n",
    "all_players_df[\"Weight\"] = all_players_df[\"Weight\"].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Converting the height to inches from feet and inches format\n",
    "height_split = all_players_df[\"Height\"].str.extract(r'(?P<feet>\\d+)\\'(?P<inches>\\d+)')\n",
    "all_players_df[\"Height\"] = height_split[\"feet\"].astype(float) * 12 + height_split[\"inches\"].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Metrics\n",
    "Before we build our classifiers, let's first define the different distance metrics we will use to measure similarity between data points. These metrics help determine how \"close\" two players are based on their stats. We'll be using 3 different metrics for comparison:\n",
    "1. Cosine Similarity\n",
    "2. Euclidean distance\n",
    "3. Mahalanobis distance\n",
    "<br>\n",
    "\n",
    "### Cosine Similarity\n",
    "Cosine similarity measures the similarity between two vectors based on the angle between them. Cosine similarity measures the similarity between two vectors based on the angle between them. It is useful when the magnitude of the values does not matter, only their direction (e.g., comparing player performance trends rather than raw numbers). We use numpy's extensive mathematical functions for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"Calculate cosine similarity between two vectors. The cosine similarity is a measure of similarity between two non-zero vectors of an inner product.\"\"\"\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean Distance\n",
    "Euclidean distance measures the straight-line distance between two points in feature space. It is the most commonly used metric for KNN as it treats all features equally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(v1, v2):\n",
    "    \"\"\"Calculate euclidean distance between two vectors. For every dimension, calculate the difference between the two vectors, square it, sum all the squared differences, and take the square root of the sum.\"\"\"\n",
    "    return np.sqrt(np.sum((np.array(v1) - np.array(v2))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis Distance\n",
    "Mahalanobis distance accounts for correlations between variables and scales the distances accordingly. Mahalanobis distance accounts for correlations between variables and scales the distances accordingly. It is particularly useful when features (e.g., height and weight) are correlated. In this case, we use a library to get the mahalanobis distance (just so that they can handle the matrix multiplication behind the scenes). Our function definition helps with inverting the covariance matrix before using the library's function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahalanobis_distance(v1, v2, cov_matrix):\n",
    "    \"\"\"Calculate the Mahalanobis distance between two vectors. The Mahalanobis distance is a measure of the distance between a point and a distribution.\"\"\"\n",
    "    inv_cov = np.linalg.inv(cov_matrix)\n",
    "    return mahalanobis(v1, v2, inv_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbour\n",
    "\n",
    "Now that all data is tidy and clean, we start with training the model using K-Nearest Neighbour (KNN). KNN is a supervised machine learning algorithm used for classification and regression. It works by finding the k closest points (neighbors) to a given data point and assigning a label based on the majority vote of those neighbors.\n",
    "\n",
    "Before applying KNN, we need to split our dataset into a **training set** and a **test set**. The training set is used to teach the model, while the test set evaluates its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let x = features\n",
    "# player_features stores an array of arrays of features of all players\n",
    "player_features = all_players_df[[\"Height\", \"Weight\", \"PPG (Points per game)\", \"RPG (Rebound per game)\", \"APG (Assists per game)\", \"PIE (Player Impact Estimate)\"]]\n",
    "\n",
    "# Let y = labels\n",
    "# player_labels stores an array of labels (1 or 0, all-stars or not) of all players\n",
    "player_labels = all_players_df[\"Label\"]\n",
    "\n",
    "# player_names stores an array of names of all players\n",
    "player_names = all_players_df[\"Name\"]\n",
    "\n",
    "# Perform train-test split with 90% training data and 10% testing data and keeping names to identify players\n",
    "x_train, x_test, y_train, y_test, train_name, test_name = train_test_split(player_features, player_labels, player_names, test_size=0.1, random_state=42)\n",
    "\n",
    "# Get the covariance matrix of the training data\n",
    "cov_matrix = np.cov(x_train, rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a function to predict labels using KNN with different distance metrics. Here's how we implemented this manually:\n",
    "\n",
    "1. **Initialization**: Choose the number of neighbors `k` and a distance metric (e.g., Euclidean, Cosine, Mahalanobis).\n",
    "\n",
    "2. **Distance Calculation**: For a new data point, calculate the distance between this point and all points in the training set using the chosen distance metric.\n",
    "\n",
    "3. **Sorting**: Sort the calculated distances in ascending order (or descending)â€”according to the metrics chosen.\n",
    "\n",
    "4. **Neighbor Selection**: Select the top `k` closest points (neighbors) from the sorted list.\n",
    "\n",
    "5. **Voting**: Count the labels of the selected `k` neighbors. The label with the highest count is the predicted label for the new data point.\n",
    "\n",
    "6. **Prediction**: Assign the predicted label to the new data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_prediction(x_train, y_train, x_test, k, metric, cov_matrx=None):\n",
    "    \"\"\"A K-Nearest Neighbors classifier that predicts the label of the test data based on the training data and a distance metric.\"\"\"\n",
    "    predictions = []\n",
    "    for test_point in x_test:\n",
    "        distances = []\n",
    "        for i, train_point in enumerate(x_train):\n",
    "            if metric == 'cosine':\n",
    "                distance = cosine_similarity(test_point, train_point)\n",
    "            elif metric == 'euclidean':\n",
    "                distance = euclidean_distance(test_point, train_point)\n",
    "            elif metric == 'mahalanobis':\n",
    "                distance = mahalanobis_distance(test_point, train_point, cov_matrix)\n",
    "            distances.append((distance, y_train[i]))\n",
    "        \n",
    "        # Sort the distances and get the k-nearest neighbors, if cosine similarity, sort in descending order to get the largest values\n",
    "        distances.sort(reverse=(1 if metric == 'cosine' else 0))\n",
    "        k_neighbours = [label for j, label in distances[:k]]\n",
    "\n",
    "        # Predict the label of the test point based on the majority label of the k-nearest neighbors\n",
    "        prediction = 1 if k_neighbours.count(1) > k_neighbours.count(0) else 0\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we perform all 3 metrics on our dataset and evaluate the model using accuracy and precision to determine how well it performs mathematically. The following is how we calculated our performance metrics:\n",
    "1. **Accuracy**: How often the model predicts correctly. [$\\frac{True\\:Positives\\:+\\:True\\:Negatives}{Number\\:of\\:Samples}$]\n",
    "<br><br>\n",
    "2. **Precision**: How many predicted positives are correct. [$\\frac{True\\:Positives}{True\\:Positives\\:+\\:False\\:Positives}$]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----K = 3-----\n",
      "Name: Donovan Mitchell, Test Label: 1, Cosine Prediction: 1, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Steven Adams, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Stanley Umude, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: DeAndre Jordan, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jalen Duren, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Evan Mobley, Test Label: 1, Cosine Prediction: 1, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Trae Young, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: DaQuan Jeffries, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Joe Ingles, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Dorian Finney-Smith, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jordan Goodwin, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jrue Holiday, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Kel'el Ware, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Paul George, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Marvin Bagley III, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jalen Williams, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: CJ McCollum, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Spencer Dinwiddie, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Corey Kispert, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Cosine Accuracy: 0.8947368421052632\n",
      "Euclidean Accuracy: 0.7894736842105263\n",
      "Mahalanobis Accuracy: 0.7894736842105263\n",
      "-----K = 5-----\n",
      "Name: Donovan Mitchell, Test Label: 1, Cosine Prediction: 1, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Steven Adams, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Stanley Umude, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: DeAndre Jordan, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jalen Duren, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Evan Mobley, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Trae Young, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: DaQuan Jeffries, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Joe Ingles, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Dorian Finney-Smith, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jordan Goodwin, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jrue Holiday, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Kel'el Ware, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Paul George, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Marvin Bagley III, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jalen Williams, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: CJ McCollum, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Spencer Dinwiddie, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Corey Kispert, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Cosine Accuracy: 0.8421052631578947\n",
      "Euclidean Accuracy: 0.7894736842105263\n",
      "Mahalanobis Accuracy: 0.7894736842105263\n",
      "-----K = 7-----\n",
      "Name: Donovan Mitchell, Test Label: 1, Cosine Prediction: 1, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Steven Adams, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Stanley Umude, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: DeAndre Jordan, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jalen Duren, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Evan Mobley, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Trae Young, Test Label: 1, Cosine Prediction: 1, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: DaQuan Jeffries, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Joe Ingles, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Dorian Finney-Smith, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jordan Goodwin, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jrue Holiday, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Kel'el Ware, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Paul George, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Marvin Bagley III, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jalen Williams, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: CJ McCollum, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Spencer Dinwiddie, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Corey Kispert, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Cosine Accuracy: 0.8947368421052632\n",
      "Euclidean Accuracy: 0.7894736842105263\n",
      "Mahalanobis Accuracy: 0.7894736842105263\n",
      "-----K = 11-----\n",
      "Name: Donovan Mitchell, Test Label: 1, Cosine Prediction: 1, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Steven Adams, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Stanley Umude, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: DeAndre Jordan, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jalen Duren, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Evan Mobley, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Trae Young, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: DaQuan Jeffries, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Joe Ingles, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Dorian Finney-Smith, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jordan Goodwin, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jrue Holiday, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Kel'el Ware, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Paul George, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Marvin Bagley III, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Jalen Williams, Test Label: 1, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: CJ McCollum, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 1, Mahalanobis Prediction: 0\n",
      "Name: Spencer Dinwiddie, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Name: Corey Kispert, Test Label: 0, Cosine Prediction: 0, Euclidean Prediction: 0, Mahalanobis Prediction: 0\n",
      "Cosine Accuracy: 0.8421052631578947\n",
      "Euclidean Accuracy: 0.7368421052631579\n",
      "Mahalanobis Accuracy: 0.7894736842105263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_accuracy(y_test, y_pred):\n",
    "    \"\"\"Calculate the accuracy of the model.\"\"\"\n",
    "    true_positives = true_negatives = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == 1 and y_pred[i] == 1:\n",
    "            true_positives += 1\n",
    "        elif y_test[i] == 0 and y_pred[i] == 0:\n",
    "            true_negatives += 1\n",
    "    \n",
    "    return (true_positives + true_negatives) / len(y_test)\n",
    "\n",
    "def get_knn_results(x_train, y_train, x_test, y_test, k_values, cov_matrix=None):\n",
    "    \"\"\"Get the K-Nearest Neighbors results for a given k and distance metric.\"\"\"\n",
    "    for k in k_values:\n",
    "        print(f\"-----K = {k}-----\")\n",
    "                \n",
    "        cosine_pred = knn_prediction(x_train, y_train, x_test, k, 'cosine')\n",
    "        euclidean_pred = knn_prediction(x_train, y_train, x_test, k, 'euclidean')\n",
    "        mahalanobis_pred = knn_prediction(x_train, y_train, x_test, k, 'mahalanobis', cov_matrix)\n",
    "\n",
    "        cosine_accuracy = calculate_accuracy(y_test, cosine_pred)\n",
    "        euclidean_accuracy = calculate_accuracy(y_test, euclidean_pred)\n",
    "        mahalanobis_accuracy = calculate_accuracy(y_test, mahalanobis_pred)\n",
    "\n",
    "        # print the test and prediction labels with names of the players in a pretty way\n",
    "        for i in range(len(y_test)):\n",
    "            print(f\"Name: {test_name.iloc[i]}, Test Label: {y_test[i]}, Cosine Prediction: {cosine_pred[i]}, Euclidean Prediction: {euclidean_pred[i]}, Mahalanobis Prediction: {mahalanobis_pred[i]}\")\n",
    "\n",
    "        # for i in range(len(y_test)):\n",
    "        #     print(f\"Name: {test_name[i]}, Test Label: {y_test[i]}, Cosine Prediction: {cosine_pred[i]}, Euclidean Prediction: {euclidean_pred[i]}, Mahalanobis Prediction: {mahalanobis_pred[i]}\")\n",
    "\n",
    "        print(f\"Cosine Accuracy: {cosine_accuracy}\")\n",
    "        print(f\"Euclidean Accuracy: {euclidean_accuracy}\")\n",
    "        print(f\"Mahalanobis Accuracy: {mahalanobis_accuracy}\")\n",
    "        \n",
    "    return 0\n",
    "\n",
    "# cosine_pred = knn_prediction(x_train.values, y_train.values, x_test.values, 5, 'cosine')\n",
    "# euclidean_pred = knn_prediction(x_train.values, y_train.values, x_test.values, 5, 'euclidean')\n",
    "# mahalanobis_pred = knn_prediction(x_train.values, y_train.values, x_test.values, 5, 'mahalanobis', cov_matrix)\n",
    "\n",
    "# cosine_accuracy = calculate_accuracy(y_test.values, cosine_pred)\n",
    "# euclidean_accuracy = calculate_accuracy(y_test.values, euclidean_pred)\n",
    "# mahalanobis_accuracy = calculate_accuracy(y_test.values, mahalanobis_pred)\n",
    "\n",
    "k_values = [3, 5, 7, 11]\n",
    "get_knn_results(x_train.values, y_train.values, x_test.values, y_test.values, k_values, cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    \"Name\": [\"Player A\", \"Player B\", \"Player C\", \"Player D\", \"Player E\"],\n",
    "    \"Weight\": [200, 220, 240, 260, 280],\n",
    "    \"Height\": [76, 78, 80, 82, 84],\n",
    "    \"PPG\": [10, 15, 20, 25, 30],\n",
    "    \"All-Stars\": [False, True, False, True, True]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Extract player names, features (X), and labels (y)\n",
    "player_names = df[\"Name\"]  \n",
    "X = df[[\"Weight\", \"Height\", \"PPG\"]]  \n",
    "y = df[\"All-Stars\"]  \n",
    "\n",
    "# Perform train-test split, keeping names\n",
    "X_train, X_test, y_train, y_test, train_names, test_names = train_test_split(X, y, player_names, test_size=0.4, random_state=42)\n",
    "\n",
    "# Convert back to DataFrames\n",
    "train_df = pd.DataFrame(X_train)\n",
    "train_df[\"Name\"] = train_names\n",
    "train_df[\"All-Stars\"] = y_train\n",
    "\n",
    "test_df = pd.DataFrame(X_test)\n",
    "test_df[\"Name\"] = test_names\n",
    "test_df[\"All-Stars\"] = y_test\n",
    "\n",
    "print(\"\\n--- Training Set ---\")\n",
    "print(train_df)\n",
    "\n",
    "print(\"\\n--- Test Set ---\")\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def dot(X, Y):\n",
    "    \"\"\"Compute the dot product of two vectors.\"\"\"\n",
    "    return sum(x * y for x, y in zip(X, Y))\n",
    "\n",
    "def norm(X):\n",
    "    \"\"\"Compute the Euclidean norm of a vector.\"\"\"\n",
    "    return sum(x ** 2 for x in X) ** 0.5\n",
    "\n",
    "def cosine_similarity(X, Y):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    return dot(X, Y) / (norm(X) * norm(Y))\n",
    "\n",
    "# Load All-Star and Non-All-Star player data\n",
    "all_stars_df = pd.read_csv('players_dataset/All_Stars.csv', header=0)\n",
    "southwest_df = pd.read_csv('players_dataset/Southwest.csv', header=0)\n",
    "southeast_df = pd.read_csv('players_dataset/Southeast.csv', header=0)\n",
    "pacific_df = pd.read_csv('players_dataset/Pacific.csv', header=0)\n",
    "northwest_df = pd.read_csv('players_dataset/Northwest.csv', header=0)\n",
    "central_df = pd.read_csv('players_dataset/Central.csv', header=0)\n",
    "atlantic_df = pd.read_csv('players_dataset/Atlantic.csv', header=0)\n",
    "\n",
    "# Combine all non-All-Star data\n",
    "divisions = [southwest_df, southeast_df, pacific_df, northwest_df, central_df, atlantic_df]\n",
    "non_all_star_df = pd.concat(divisions, ignore_index=True)\n",
    "\n",
    "# Assign labels\n",
    "all_stars_df[\"Label\"] = 1  # All-Star\n",
    "non_all_star_df[\"Label\"] = 0  # Non-All-Star\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat([all_stars_df, non_all_star_df], ignore_index=True)\n",
    "\n",
    "# Convert weight to numeric (removing 'lb')\n",
    "data[\"Weight\"] = data[\"Weight\"].str.extract(r'(\\d+)').astype(float)\n",
    "\n",
    "# Convert height to inches\n",
    "height_split = data[\"Height\"].str.extract(r'(?P<feet>\\d+)\\'(?P<inches>\\d+)')\n",
    "data[\"Height\"] = height_split[\"feet\"].astype(float) * 12 + height_split[\"inches\"].astype(float)\n",
    "\n",
    "# Select relevant numerical columns\n",
    "features = [\"Weight\", \"Height\", \"PPG (Points per game)\", \"RPG (Rebound per game)\", \"APG (Assists per game)\", \"PIE (Player Impact Estimate)\"]\n",
    "players_stats_original = data[features].apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "\n",
    "# Extract labels\n",
    "labels = data[\"Label\"].to_numpy()\n",
    "\n",
    "# k-NN Classification with predefined k values\n",
    "def predict_all_star(new_player, k):\n",
    "    new_player = np.array(new_player)\n",
    "    dataset = players_stats_original.to_numpy()\n",
    "    \n",
    "    # Compute similarities to all players\n",
    "    similarities = [(cosine_similarity(new_player, dataset[i]), labels[i], data.iloc[i][\"Name\"], *players_stats_original.iloc[i]) for i in range(len(dataset))]\n",
    "    \n",
    "    # Sort by highest similarity (descending order)\n",
    "    sorted_similarities = sorted(similarities, key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    # Select top-k nearest neighbors\n",
    "    top_k = sorted_similarities[:k]\n",
    "    \n",
    "    # Count votes\n",
    "    all_star_votes = sum(1 for sim in top_k if sim[1] == 1)\n",
    "    not_all_star_votes = sum(1 for sim in top_k if sim[1] == 0)\n",
    "    \n",
    "    # Determine final classification\n",
    "    prediction = \"All-Star\" if all_star_votes > not_all_star_votes else \"Not All-Star\"\n",
    "    \n",
    "    return prediction, top_k\n",
    "\n",
    "\n",
    "\n",
    "def get_valid_input(prompt, convert_func=float):\n",
    "    while True:\n",
    "        try:\n",
    "            value = convert_func(input(prompt))\n",
    "            return value\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid value.\")\n",
    "\n",
    "# print(\"Enter player stats:\")\n",
    "name = input(\"Name: \")\n",
    "weight = get_valid_input(\"Weight (lbs): \")\n",
    "feet = get_valid_input(\"Height (feet): \", int)\n",
    "inches = get_valid_input(\"Height (inches): \", int)\n",
    "height = feet * 12 + inches\n",
    "ppg = get_valid_input(\"PPG (Points per game): \")\n",
    "rpg = get_valid_input(\"RPG (Rebound per game): \")\n",
    "apg = get_valid_input(\"APG (Assists per game): \")\n",
    "pie = get_valid_input(\"PIE (Player Impact Estimate): \")\n",
    "\n",
    "new_player = [weight, height, ppg, rpg, apg, pie]\n",
    "\n",
    "# Predict for k values 7, 9, and 11\n",
    "for k in [7, 9, 11]:\n",
    "    prediction, top_k = predict_all_star(new_player, k)\n",
    "    print(f\"\\nK = {k}\")\n",
    "    print(f\"{'Name':<15}{'Weight':<10}{'Height':<10}{'PPG':<10}{'RPG':<10}{'APG':<10}{'PIE':<10}{'Cosine Similarity':<20}{'Label':<15}\")\n",
    "    for player in top_k:\n",
    "        label = \"All-Star\" if player[1] == 1 else \"Not All-Star\"\n",
    "        print(f\"{player[2]:<15}{player[3]:<10.2f}{player[4]:<10.2f}{player[5]:<10.2f}{player[6]:<10.2f}{player[7]:<10.2f}{player[8]:<10.2f}{player[0]:<20.4f}{label:<15}\")\n",
    "    print(f\"{name:<15}{weight:<10.2f}{height:<10.2f}{ppg:<10.2f}{rpg:<10.2f}{apg:<10.2f}{pie:<10.2f}{'':<20}{prediction:<15}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for calculating the euclidian distance of two points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidian_distance(arr1, arr2):\n",
    "    # should be able to take in 2 array (or any number of values) and return the euclidian distance between them\n",
    "    a1 = np.array(arr1)\n",
    "    a2 = np.array(arr2)\n",
    "    return np.sqrt(np.sum((a1 - a2)**2))\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions for the centroid classifier, checks for euclidian and cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start for centroid classifier\n",
    "def centroid_classifier(new_player):\n",
    "    # Calculate average statistics for All-Stars and Non-All-Stars directly from the DataFrames and change it to a numpy array\n",
    "    all_star_averages = all_stars_df[features].mean().to_numpy()\n",
    "    non_all_star_averages = non_all_star_df[features].mean().to_numpy()\n",
    "    \n",
    "    centroid_check_euclidian(new_player,all_star_averages,non_all_star_averages)\n",
    "    centroid_check_cosine(new_player,all_star_averages,non_all_star_averages)\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with euclidian distance\n",
    "def centroid_check_euclidian(new_player, all_star_avg, non_all_satr_avg):\n",
    "    # Calculate Euclidean distances to both centroids\n",
    "    euclidian_distance_to_all_star = euclidian_distance(new_player, all_star_avg)\n",
    "    eudlidian_distance_to_non_all_star = euclidian_distance(new_player, non_all_satr_avg)\n",
    "\n",
    "    # Classify based on the closer centroid\n",
    "    if euclidian_distance_to_all_star < eudlidian_distance_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with cosine similarity\n",
    "def centroid_check_cosine(new_player, all_star_avg, non_all_satr_avg):\n",
    "    cosine_similarity_to_all_star = cosine_similarity(new_player, all_star_avg)\n",
    "    cosine_similarity_to_non_all_star = cosine_similarity(new_player, non_all_satr_avg)\n",
    "    \n",
    "    # Classify based on which centroid is larger (closer to 1)\n",
    "    if cosine_similarity_to_all_star > cosine_similarity_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "# Check similarity between the average of the dataset and the new point with mahalobis distance\n",
    "def centroid_mahalobis_distance(new_player, all_star_avg, non_all_satr_avg):\n",
    "    mahalobis_distance_to_all_star = mahalobis_distance(new_player, all_star_avg)\n",
    "    mahalobis_distance_to_non_all_star = mahalobis_distance(new_player, non_all_satr_avg)\n",
    "    \n",
    "    # Classify based on the closer centroid\n",
    "    if mahalobis_distance_to_all_star < mahalobis_distance_to_non_all_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
